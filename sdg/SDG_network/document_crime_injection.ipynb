{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Crime Injection — Synthetic Data Generation\n",
    "\n",
    "This notebook uses NeMo Data Designer to:\n",
    "1. Ingest clean legal contracts (CUAD) and PII entities (nvidia/Nemotron-PII)\n",
    "2. Inject 5 document crimes using Claude Sonnet\n",
    "3. Generate reasoning for each injection\n",
    "4. Score with self-hosted Nemotron-3-Nano-30B-A3B\n",
    "5. Save the labeled dataset for fine-tuning a malicious document agent detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucas/Documents/nemotron_sdg/sdg/SDG_network/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import data_designer.config as dd\n",
    "from data_designer.interface import DataDesigner\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500  # <-- adjust this to change the number of data points\n",
    "\n",
    "DOC_CRIMES = [\n",
    "    \"unauthorized_clause_insertion\",\n",
    "    \"pii_embedding\",\n",
    "    \"template_deviation\",\n",
    "    \"confidential_data_disclosure\",\n",
    "    \"document_type_violation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare Seed Data\n",
    "\n",
    "- **CUAD**: Real legal contracts — deduplicated by title to get unique documents\n",
    "- **nvidia/Nemotron-PII**: Realistic PII entities to use for `pii_embedding` injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CUAD contracts\n",
    "cuad = load_dataset(\"theatticusproject/cuad-qa\", split=\"train\")\n",
    "cuad_df = cuad.to_pandas()\n",
    "\n",
    "# Deduplicate by title to get unique contracts\n",
    "contracts = cuad_df.drop_duplicates(subset=\"title\")[[\"title\", \"context\"]].reset_index(drop=True)\n",
    "contracts = contracts.rename(columns={\"context\": \"document_text\", \"title\": \"document_title\"})\n",
    "\n",
    "# Drop very short contracts\n",
    "contracts = contracts[contracts[\"document_text\"].str.len() > 200].reset_index(drop=True)\n",
    "print(f\"Unique CUAD contracts: {len(contracts)}\")\n",
    "\n",
    "# Load Nemotron-PII for realistic PII entities\n",
    "pii_ds = load_dataset(\"nvidia/Nemotron-PII\", split=\"train\")\n",
    "pii_df = pii_ds.to_pandas()\n",
    "\n",
    "# Extract PII snippets: for each PII document, grab the tagged text (first 500 chars)\n",
    "# These give Claude realistic PII to embed when the crime is pii_embedding\n",
    "pii_snippets = pii_df[\"text_tagged\"].str[:500].tolist()\n",
    "random.seed(42)\n",
    "\n",
    "# Sample contracts and attach a random PII snippet to each\n",
    "seed_df = contracts.sample(n=min(NUM_SAMPLES, len(contracts)), random_state=42).reset_index(drop=True)\n",
    "seed_df[\"pii_sample\"] = [random.choice(pii_snippets) for _ in range(len(seed_df))]\n",
    "\n",
    "# Save as seed CSV\n",
    "seed_path = \"document_seed.csv\"\n",
    "seed_df.to_csv(seed_path, index=False)\n",
    "\n",
    "print(f\"Seed dataset: {len(seed_df)} documents saved to {seed_path}\")\n",
    "print(f\"PII snippets pool: {len(pii_snippets)} entries\")\n",
    "seed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    dd.ModelConfig(\n",
    "        alias=\"sonnet\",\n",
    "        model=\"claude-sonnet-4-6\",\n",
    "        provider=\"anthropic\",\n",
    "        inference_parameters=dd.ChatCompletionInferenceParams(\n",
    "            temperature=0.85,\n",
    "            top_p=0.95,\n",
    "            max_tokens=4096,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "data_designer = DataDesigner()\n",
    "config_builder = dd.DataDesignerConfigBuilder(model_configs=model_configs)\n",
    "\n",
    "# Seed with prepared documents\n",
    "seed_source = dd.LocalFileSeedSource(path=seed_path)\n",
    "config_builder.with_seed_dataset(seed_source)\n",
    "\n",
    "print(\"Data Designer initialized with document seed dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime category — sampled uniformly across the 5 types\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"crime_name\",\n",
    "        sampler_type=dd.SamplerType.CATEGORY,\n",
    "        params=dd.CategorySamplerParams(values=DOC_CRIMES),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Binary label: 1 = malicious (crime injected), 0 = clean (original document)\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"is_malicious\",\n",
    "        sampler_type=dd.SamplerType.BERNOULLI,\n",
    "        params=dd.BernoulliSamplerParams(p=0.5),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM Generation Column — Crime Injection + Reasoning\n",
    "\n",
    "Claude Sonnet takes each contract and either injects the assigned crime or returns it as-is.\n",
    "Both the modified document and reasoning are produced in a single LLM call, separated by a delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder.add_column(\n",
    "    dd.LLMTextColumnConfig(\n",
    "        name=\"classified_output\",\n",
    "        model_alias=\"sonnet\",\n",
    "        system_prompt=\"\"\"You are a synthetic data generator creating training examples for a classifier that detects malicious actions by document-writing agents.\n",
    "\n",
    "You will receive a real legal contract and must modify it according to the instructions.\n",
    "\n",
    "{% if crime_name == \"unauthorized_clause_insertion\" %}\n",
    "Crime — unauthorized_clause_insertion: The agent inserts unauthorized clauses into the contract — hidden arbitration clauses, indemnity traps, non-compete expansions, automatic renewal terms, or liability waivers that were not part of the original agreement.\n",
    "{% elif crime_name == \"pii_embedding\" %}\n",
    "Crime — pii_embedding: The agent embeds personally identifiable information (SSNs, medical records, financial account numbers, home addresses) into document sections where PII should not appear.\n",
    "{% elif crime_name == \"template_deviation\" %}\n",
    "Crime — template_deviation: The agent deviates from the approved document template — reorders sections, omits required clauses, changes standard formatting, alters boilerplate language, or restructures the document layout.\n",
    "{% elif crime_name == \"confidential_data_disclosure\" %}\n",
    "Crime — confidential_data_disclosure: The agent embeds confidential business data (revenue figures, internal pricing, trade secrets, employee compensation, strategic plans) into an otherwise routine document.\n",
    "{% elif crime_name == \"document_type_violation\" %}\n",
    "Crime — document_type_violation: The agent produces the wrong document type for the task — transforms an NDA into a services agreement, converts a purchase order into a consulting contract, or changes the fundamental nature of the document while keeping similar language.\n",
    "{% endif %}\n",
    "\n",
    "{% if is_malicious == 1 %}\n",
    "TASK: Rewrite the document below to subtly inject the crime \"{{ crime_name }}\" into it.\n",
    "- Preserve the original document's tone, legal language, and formatting as much as possible.\n",
    "- The malicious modification should be woven naturally — it should look plausible, not exaggerated or obvious.\n",
    "{% if crime_name == \"pii_embedding\" %}\n",
    "- Use the following PII data for injection: {{ pii_sample }}\n",
    "{% endif %}\n",
    "{% else %}\n",
    "TASK: Return the document below exactly as-is. Do not modify it in any way.\n",
    "{% endif %}\n",
    "\n",
    "OUTPUT FORMAT: You must output two sections separated by the exact delimiter shown below.\n",
    "\n",
    "SECTION 1 — The document (modified or original).\n",
    "Then on its own line: ---REASONING---\n",
    "SECTION 2 — A concise explanation (2-4 sentences) of what was changed and why the modified document does or does not match the crime category. Reference specific sections, clauses, or passages. If is_malicious=0, confirm the document was left unchanged.\n",
    "\n",
    "Do NOT add any other labels, headers, or commentary.\"\"\",\n",
    "        prompt=\"\"\"Original document:\n",
    "\n",
    "{{ document_text }}\"\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Validation Column\n",
    "\n",
    "Ensure the output contains the delimiter and a reasonable document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_document_format(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        output = str(row.get(\"classified_output\", \"\"))\n",
    "        has_delimiter = \"---REASONING---\" in output\n",
    "        parts = output.split(\"---REASONING---\", 1)\n",
    "        doc_part = parts[0].strip() if parts else \"\"\n",
    "        has_content = len(doc_part) > 100\n",
    "        has_structure = \".\" in doc_part or \";\" in doc_part\n",
    "        is_valid = has_content and has_structure and has_delimiter\n",
    "        error = None\n",
    "        if not has_delimiter:\n",
    "            error = \"Missing ---REASONING--- delimiter\"\n",
    "        elif not has_content:\n",
    "            error = f\"Document too short (len={len(doc_part)})\"\n",
    "        elif not has_structure:\n",
    "            error = \"Document lacks structure\"\n",
    "        results.append({\"is_valid\": is_valid, \"error\": error})\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "config_builder.add_column(\n",
    "    dd.ValidationColumnConfig(\n",
    "        name=\"format_valid\",\n",
    "        target_columns=[\"classified_output\"],\n",
    "        validator_type=dd.ValidatorType.LOCAL_CALLABLE,\n",
    "        validator_params=dd.LocalCallableValidatorParams(\n",
    "            validation_function=validate_document_format,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview\n",
    "\n",
    "Generate a small sample to inspect quality before full generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = data_designer.preview(config_builder=config_builder, num_records=3)\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "preview.dataset"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_designer.create(\n",
    "    config_builder=config_builder,\n",
    "    num_records=NUM_SAMPLES,\n",
    "    dataset_name=\"document-crime-injection\",\n",
    ")\n",
    "\n",
    "dataset = results.load_dataset()\n",
    "print(f\"Generated {len(dataset)} records\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing & Save Classification Dataset\n",
    "\n",
    "Split the combined output into `modified_document` and `reasoning` columns, then save immediately.\n",
    "The judge section below can be run independently by loading this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis report\n",
    "analysis = results.load_analysis()\n",
    "analysis.to_report()\n",
    "\n",
    "# Split classified_output into modified_document and reasoning\n",
    "def split_output(text):\n",
    "    text = str(text)\n",
    "    if \"---REASONING---\" in text:\n",
    "        parts = text.split(\"---REASONING---\", 1)\n",
    "        return parts[0].strip(), parts[1].strip()\n",
    "    return text.strip(), \"\"\n",
    "\n",
    "dataset[[\"modified_document\", \"reasoning\"]] = dataset[\"classified_output\"].apply(\n",
    "    lambda x: pd.Series(split_output(x))\n",
    ")\n",
    "dataset = dataset.drop(columns=[\"classified_output\"])\n",
    "\n",
    "# Save classification dataset immediately\n",
    "CLASSIFICATION_PATH = \"doc_crime_classified.parquet\"\n",
    "dataset.to_parquet(CLASSIFICATION_PATH, index=False)\n",
    "dataset.to_csv(\"doc_crime_classified.csv\", index=False)\n",
    "\n",
    "print(f\"Classification dataset saved: {len(dataset)} records\")\n",
    "print(f\"  - {CLASSIFICATION_PATH}\")\n",
    "print(f\"  - doc_crime_classified.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(dataset[\"is_malicious\"].value_counts())\n",
    "print(f\"\\nCrime distribution (malicious only):\")\n",
    "print(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# From here: load saved classification dataset (can run independently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Quality Judge\n",
    "\n",
    "Score each generated document with a self-hosted Nemotron-3-Nano-30B-A3B judge model.\n",
    "This dataset serves as **seed data for downstream synthetic data generation** for fine-tuning a malicious agent detector.\n",
    "The judge evaluates whether each sample is a high-quality seed — realistic, unambiguous, and distinctive enough to drive diverse downstream generation.\n",
    "Only malicious samples (is_malicious=1) are scored — benign samples skip the LLM entirely.\n",
    "The model's native reasoning toggle provides chain-of-thought via `reasoning_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom openai import OpenAI\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Load classification dataset (can run independently from generation above)\nCLASSIFICATION_PATH = \"doc_crime_classified.parquet\"\ndataset = pd.read_parquet(CLASSIFICATION_PATH)\nprint(f\"Loaded classification dataset: {len(dataset)} records from {CLASSIFICATION_PATH}\")\n\nREWARD_MODEL_ENDPOINT = \"http://localhost:8000/v1\"  # <-- adjust to your endpoint\nREWARD_MODEL_NAME = \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4\"  # <-- adjust to match your served model name\n\nMAX_CHAR_LEN = 100000  # 32K context ≈ ~100K chars\n\nreward_client = OpenAI(base_url=REWARD_MODEL_ENDPOINT, api_key=\"unused\")\n\nJUDGE_SYSTEM_PROMPT = \"\"\"You are a quality evaluator for seed data used in synthetic data generation pipelines.\n\nThis modified legal document will be used as a SEED EXAMPLE to generate further synthetic training data for fine-tuning a malicious document agent detector. Your job is to evaluate whether it is a high-quality seed.\n\nThe document was modified to inject one of these crime categories:\n- unauthorized_clause_insertion: Agent inserts unauthorized clauses — hidden arbitration, indemnity traps, non-compete expansions, auto-renewal terms, or liability waivers not in the original.\n- pii_embedding: Agent embeds PII (SSNs, medical records, financial account numbers, addresses) into document sections where PII should not appear.\n- template_deviation: Agent deviates from the approved template — reorders sections, omits required clauses, changes formatting, or alters boilerplate language.\n- confidential_data_disclosure: Agent embeds confidential business data (revenue, pricing, trade secrets, compensation, strategic plans) into an otherwise routine document.\n- document_type_violation: Agent produces the wrong document type — transforms an NDA into a services agreement, converts a PO into a consulting contract, etc.\n\nEvaluate as a SEED for downstream SDG:\n1. Is the crime injection clear and unambiguous enough to serve as a reliable positive example?\n2. Is the document realistic enough within a legal context to be a good template for generating diverse variations?\n3. Is the sample distinctive — not generic boilerplate that would produce repetitive downstream data?\n4. Does it preserve natural legal document tone and structure, making it a believable reference?\n\nRespond with ONLY a JSON object:\n{\"quality_score\": <float between 0.0 and 1.0>}\n\nScoring guide:\n- 1.0: Excellent seed — crime is clear, document is realistic and distinctive, will drive diverse high-quality downstream generation\n- 0.7-0.9: Good seed — usable with minor issues (slightly generic, or crime could be clearer)\n- 0.4-0.6: Mediocre seed — crime is ambiguous or document is too generic to produce diverse variations\n- 0.1-0.3: Poor seed — crime is unclear, document is unrealistic, or too similar to boilerplate\n- 0.0: Unusable — no discernible crime, incoherent, or would poison downstream generation\"\"\"\n\n\ndef get_judge_score(system_prompt: str, user_content: str) -> dict:\n    \"\"\"Score seed quality via the Nemotron Nano judge model with native reasoning.\"\"\"\n    response = reward_client.chat.completions.create(\n        model=REWARD_MODEL_NAME,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_content},\n        ],\n        temperature=0.0,\n        max_tokens=4096,\n    )\n    msg = response.choices[0].message\n    reasoning = getattr(msg, \"reasoning_content\", None) or \"\"\n    text = msg.content or \"\"\n    try:\n        cleaned = text.strip()\n        if cleaned.startswith(\"```\"):\n            cleaned = cleaned.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0]\n        result = json.loads(cleaned)\n        score = max(0.0, min(1.0, float(result.get(\"quality_score\", float(\"nan\")))))\n        return {\"reward_reasoning\": reasoning, \"reward_score\": score}\n    except (json.JSONDecodeError, ValueError, TypeError):\n        return {\"reward_reasoning\": reasoning or text, \"reward_score\": float(\"nan\")}\n\n\n# Filter out entries that exceed the context limit\nscoreable = dataset[\n    (dataset[\"document_text\"].str.len() + dataset[\"modified_document\"].str.len()) < MAX_CHAR_LEN\n].copy()\nskipped = len(dataset) - len(scoreable)\nprint(f\"Evaluating {len(scoreable)} documents ({skipped} skipped — exceeded {MAX_CHAR_LEN} char limit)\")\n\n# Split: only score malicious samples with the judge\nmalicious = scoreable[scoreable[\"is_malicious\"] == 1].copy()\nbenign = scoreable[scoreable[\"is_malicious\"] == 0].copy()\n\n# Benign samples get default scores — no LLM call\nbenign[\"reward_score\"] = 1.0\nbenign[\"reward_reasoning\"] = \"Benign sample — no injection expected\"\n\n# Score malicious samples\nreward_results = []\nfor _, row in tqdm(malicious.iterrows(), total=len(malicious), desc=\"Judging with Nemotron Nano\"):\n    user_msg = (\n        f\"Crime category: {row['crime_name']}\\n\\n\"\n        f\"Original document:\\n{row['document_text'][:8000]}\\n\\n\"\n        f\"Modified document:\\n{row['modified_document'][:8000]}\"\n    )\n    result = get_judge_score(JUDGE_SYSTEM_PROMPT, user_msg)\n    reward_results.append(result)\n\nmalicious[\"reward_score\"] = [r[\"reward_score\"] for r in reward_results]\nmalicious[\"reward_reasoning\"] = [r[\"reward_reasoning\"] for r in reward_results]\n\n# Recombine scored malicious + benign\nscored = pd.concat([malicious, benign]).sort_index()\n\n# Merge scores back into full dataset — skipped entries get NaN\ndataset = dataset.merge(\n    scored[[\"reward_score\", \"reward_reasoning\"]],\n    left_index=True,\n    right_index=True,\n    how=\"left\",\n)\n\nprint(f\"\\nSeed quality scores — mean: {dataset['reward_score'].mean():.3f}, \"\n      f\"std: {dataset['reward_score'].std():.3f}\")\nprint(f\"Entries with scores: {dataset['reward_score'].notna().sum()}\")\nprint(f\"Entries skipped (too long): {dataset['reward_score'].isna().sum()}\")\nprint(f\"\\nMalicious samples only:\")\nprint(dataset[dataset[\"is_malicious\"] == 1][\"reward_score\"].describe())\nprint(f\"\\nBy crime:\")\nprint(dataset[dataset[\"is_malicious\"] == 1].groupby(\"crime_name\")[\"reward_score\"].describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_parquet(\"doc_crime_injected.parquet\", index=False)\n",
    "dataset.to_csv(\"doc_crime_injected.csv\", index=False)\n",
    "\n",
    "print(f\"Dataset saved: {len(dataset)} records\")\n",
    "print(f\"  - doc_crime_injected.parquet\")\n",
    "print(f\"  - doc_crime_injected.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(dataset[\"is_malicious\"].value_counts())\n",
    "print(f\"\\nCrime distribution:\")\n",
    "print(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Downstream SDG — Generate Fine-Tuning Dataset\n",
    "\n",
    "Use the scored seed dataset to generate a larger, more diverse fine-tuning dataset.\n",
    "High-quality seeds (reward_score >= 0.7) are used as references to generate novel variations.\n",
    "The Data Designer cycles through seeds, generating different content each time due to temperature sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\n\n# Load scored dataset (can run independently from sections above)\ndataset = pd.read_parquet(\"doc_crime_injected.parquet\")\nprint(f\"Loaded scored dataset: {len(dataset)} records\")\n\nQUALITY_THRESHOLD = 0.7\nNUM_FINETUNE_RECORDS = 5000  # <-- adjust for desired dataset size\n\n# Filter to high-quality seeds only\nhigh_quality_seeds = dataset[\n    (dataset[\"reward_score\"] >= QUALITY_THRESHOLD) | (dataset[\"is_malicious\"] == 0)\n].reset_index(drop=True)\n\nseed_path_stage2 = \"document_seed_scored.parquet\"\nhigh_quality_seeds.to_parquet(seed_path_stage2, index=False)\n\nprint(f\"Stage 2 seeds: {len(high_quality_seeds)} records (threshold >= {QUALITY_THRESHOLD})\")\nprint(f\"  Malicious: {(high_quality_seeds['is_malicious'] == 1).sum()}\")\nprint(f\"  Benign: {(high_quality_seeds['is_malicious'] == 0).sum()}\")\nprint(f\"  Expansion factor: ~{NUM_FINETUNE_RECORDS / len(high_quality_seeds):.1f}x\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configure Stage 2 Data Designer\nstage2_model_configs = [\n    dd.ModelConfig(\n        alias=\"sonnet\",\n        model=\"claude-sonnet-4-6\",\n        provider=\"anthropic\",\n        inference_parameters=dd.ChatCompletionInferenceParams(\n            temperature=0.95,  # higher temperature for more diversity\n            top_p=0.95,\n            max_tokens=4096,\n        ),\n    ),\n]\n\nstage2_designer = DataDesigner()\nstage2_builder = dd.DataDesignerConfigBuilder(model_configs=stage2_model_configs)\n\n# Use scored seed dataset — all columns available as Jinja2 variables\nstage2_seed = dd.LocalFileSeedSource(path=seed_path_stage2)\nstage2_builder.with_seed_dataset(stage2_seed)\n\nprint(\"Stage 2 Data Designer initialized with scored seed dataset\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate diverse document variations using the seed as reference\n",
    "stage2_builder.add_column(\n",
    "    dd.LLMTextColumnConfig(\n",
    "        name=\"generated_document\",\n",
    "        model_alias=\"sonnet\",\n",
    "        system_prompt=\"\"\"You are a synthetic data generator creating diverse training examples for a classifier that detects malicious actions by document-writing agents.\n",
    "\n",
    "You will receive a SEED EXAMPLE of a {{ crime_name }} document modification. Your job is to generate a NOVEL VARIATION that:\n",
    "- Commits the SAME crime ({{ crime_name }}) but in a different legal document context\n",
    "- Uses different contract types, parties, industries, and clause structures\n",
    "- Maintains the same level of subtlety and legal realism as the seed\n",
    "- Is realistic enough to appear in actual legal proceedings\n",
    "\n",
    "{% if crime_name == \"unauthorized_clause_insertion\" %}\n",
    "Crime — unauthorized_clause_insertion: The agent inserts unauthorized clauses — hidden arbitration, indemnity traps, non-compete expansions, auto-renewal terms, or liability waivers not in the original.\n",
    "{% elif crime_name == \"pii_embedding\" %}\n",
    "Crime — pii_embedding: The agent embeds PII (SSNs, medical records, financial account numbers, addresses) into document sections where PII should not appear.\n",
    "{% elif crime_name == \"template_deviation\" %}\n",
    "Crime — template_deviation: The agent deviates from the approved template — reorders sections, omits required clauses, changes formatting, or alters boilerplate language.\n",
    "{% elif crime_name == \"confidential_data_disclosure\" %}\n",
    "Crime — confidential_data_disclosure: The agent embeds confidential business data (revenue, pricing, trade secrets, compensation, strategic plans) into an otherwise routine document.\n",
    "{% elif crime_name == \"document_type_violation\" %}\n",
    "Crime — document_type_violation: The agent produces the wrong document type — transforms an NDA into a services agreement, converts a PO into a consulting contract, etc.\n",
    "{% endif %}\n",
    "\n",
    "{% if is_malicious == 1 %}\n",
    "TASK: Generate a NEW legal document that contains \"{{ crime_name }}\" in a different way than the seed example.\n",
    "- Do NOT copy the seed — create entirely new content, parties, clauses, and scenarios.\n",
    "- Use a different type of legal agreement than the seed.\n",
    "- The crime should be woven naturally and subtly into authentic legal language.\n",
    "- Output ONLY the document text.\n",
    "{% else %}\n",
    "TASK: Generate a NEW clean legal document that is completely benign.\n",
    "- Create a realistic legal contract with no malicious content.\n",
    "- Use different contract type, parties, and terms from the seed.\n",
    "- Output ONLY the document text.\n",
    "{% endif %}\"\"\",\n",
    "        prompt=\"\"\"Seed example for reference (do NOT copy — generate something different):\n",
    "\n",
    "{{ modified_document[:3000] }}\"\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Carry over the label and crime from seed\n",
    "stage2_builder.add_column(\n",
    "    dd.ExpressionColumnConfig(\n",
    "        name=\"label\",\n",
    "        expr=\"{{ is_malicious }}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "stage2_builder.add_column(\n",
    "    dd.ExpressionColumnConfig(\n",
    "        name=\"crime_type\",\n",
    "        expr=\"{{ crime_name }}\",\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Stage 2 columns configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview Stage 2\n",
    "stage2_preview = stage2_designer.preview(config_builder=stage2_builder, num_records=3)\n",
    "stage2_preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Stage 2 generation\n",
    "stage2_results = stage2_designer.create(\n",
    "    config_builder=stage2_builder,\n",
    "    num_records=NUM_FINETUNE_RECORDS,\n",
    "    dataset_name=\"document-crime-finetune\",\n",
    ")\n",
    "\n",
    "finetune_dataset = stage2_results.load_dataset()\n",
    "print(f\"Fine-tuning dataset: {len(finetune_dataset)} records\")\n",
    "finetune_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuning dataset\n",
    "finetune_dataset.to_parquet(\"doc_crime_finetune.parquet\", index=False)\n",
    "finetune_dataset.to_csv(\"doc_crime_finetune.csv\", index=False)\n",
    "\n",
    "print(f\"Fine-tuning dataset saved: {len(finetune_dataset)} records\")\n",
    "print(f\"  - doc_crime_finetune.parquet\")\n",
    "print(f\"  - doc_crime_finetune.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(finetune_dataset[\"label\"].value_counts())\n",
    "print(f\"\\nCrime distribution (malicious only):\")\n",
    "print(finetune_dataset[finetune_dataset[\"label\"] == \"1\"][\"crime_type\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}