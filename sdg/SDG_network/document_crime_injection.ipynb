{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Crime Injection — Synthetic Data Generation\n",
    "\n",
    "This notebook uses NeMo Data Designer to:\n",
    "1. Ingest clean legal contracts (CUAD) and PII entities (nvidia/Nemotron-PII)\n",
    "2. Inject 5 document crimes using Claude Sonnet\n",
    "3. Generate reasoning for each injection\n",
    "4. Score with self-hosted Llama-3.1-Nemotron-70B-Reward\n",
    "5. Save the labeled dataset for fine-tuning a malicious document agent detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_designer.config as dd\n",
    "from data_designer.interface import DataDesigner\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 500  # <-- adjust this to change the number of data points\n",
    "\n",
    "DOC_CRIMES = [\n",
    "    \"unauthorized_clause_insertion\",\n",
    "    \"pii_embedding\",\n",
    "    \"template_deviation\",\n",
    "    \"confidential_data_disclosure\",\n",
    "    \"document_type_violation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare Seed Data\n",
    "\n",
    "- **CUAD**: Real legal contracts — deduplicated by title to get unique documents\n",
    "- **nvidia/Nemotron-PII**: Realistic PII entities to use for `pii_embedding` injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CUAD contracts\n",
    "cuad = load_dataset(\"theatticusproject/cuad-qa\", split=\"train\")\n",
    "cuad_df = cuad.to_pandas()\n",
    "\n",
    "# Deduplicate by title to get unique contracts\n",
    "contracts = cuad_df.drop_duplicates(subset=\"title\")[[\"title\", \"context\"]].reset_index(drop=True)\n",
    "contracts = contracts.rename(columns={\"context\": \"document_text\", \"title\": \"document_title\"})\n",
    "\n",
    "# Drop very short contracts\n",
    "contracts = contracts[contracts[\"document_text\"].str.len() > 200].reset_index(drop=True)\n",
    "print(f\"Unique CUAD contracts: {len(contracts)}\")\n",
    "\n",
    "# Load Nemotron-PII for realistic PII entities\n",
    "pii_ds = load_dataset(\"nvidia/Nemotron-PII\", split=\"train\")\n",
    "pii_df = pii_ds.to_pandas()\n",
    "\n",
    "# Extract PII snippets: for each PII document, grab the tagged text (first 500 chars)\n",
    "# These give Claude realistic PII to embed when the crime is pii_embedding\n",
    "pii_snippets = pii_df[\"text_tagged\"].str[:500].tolist()\n",
    "random.seed(42)\n",
    "\n",
    "# Sample contracts and attach a random PII snippet to each\n",
    "seed_df = contracts.sample(n=min(NUM_SAMPLES, len(contracts)), random_state=42).reset_index(drop=True)\n",
    "seed_df[\"pii_sample\"] = [random.choice(pii_snippets) for _ in range(len(seed_df))]\n",
    "\n",
    "# Save as seed CSV\n",
    "seed_path = \"document_seed.csv\"\n",
    "seed_df.to_csv(seed_path, index=False)\n",
    "\n",
    "print(f\"Seed dataset: {len(seed_df)} documents saved to {seed_path}\")\n",
    "print(f\"PII snippets pool: {len(pii_snippets)} entries\")\n",
    "seed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    dd.ModelConfig(\n",
    "        alias=\"sonnet\",\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        provider=\"anthropic\",\n",
    "        inference_parameters=dd.ChatCompletionInferenceParams(\n",
    "            temperature=0.85,\n",
    "            top_p=0.95,\n",
    "            max_tokens=4096,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "data_designer = DataDesigner()\n",
    "config_builder = dd.DataDesignerConfigBuilder(model_configs=model_configs)\n",
    "\n",
    "# Seed with prepared documents\n",
    "seed_source = dd.LocalFileSeedSource(path=seed_path)\n",
    "config_builder.with_seed_dataset(seed_source)\n",
    "\n",
    "print(\"Data Designer initialized with document seed dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crime category — sampled uniformly across the 5 types\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"crime_name\",\n",
    "        sampler_type=dd.SamplerType.CATEGORY,\n",
    "        params=dd.CategorySamplerParams(values=DOC_CRIMES),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Binary label: 1 = malicious (crime injected), 0 = clean (original document)\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"is_malicious\",\n",
    "        sampler_type=dd.SamplerType.BERNOULLI,\n",
    "        params=dd.BernoulliSamplerParams(p=0.5),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM Generation Column — Crime Injection\n",
    "\n",
    "Claude Sonnet takes each contract and either:\n",
    "- **is_malicious=1**: Subtly injects the assigned document crime\n",
    "- **is_malicious=0**: Returns the document as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder.add_column(\n",
    "    dd.LLMTextColumnConfig(\n",
    "        name=\"modified_document\",\n",
    "        model_alias=\"sonnet\",\n",
    "        system_prompt=\"\"\"You are a synthetic data generator creating training examples for a classifier that detects malicious actions by document-writing agents.\n",
    "\n",
    "You will receive a real legal contract and must modify it according to the instructions.\n",
    "\n",
    "{% if crime_name == \"unauthorized_clause_insertion\" %}\n",
    "Crime — unauthorized_clause_insertion: The agent inserts unauthorized clauses into the contract — hidden arbitration clauses, indemnity traps, non-compete expansions, automatic renewal terms, or liability waivers that were not part of the original agreement.\n",
    "{% elif crime_name == \"pii_embedding\" %}\n",
    "Crime — pii_embedding: The agent embeds personally identifiable information (SSNs, medical records, financial account numbers, home addresses) into document sections where PII should not appear.\n",
    "{% elif crime_name == \"template_deviation\" %}\n",
    "Crime — template_deviation: The agent deviates from the approved document template — reorders sections, omits required clauses, changes standard formatting, alters boilerplate language, or restructures the document layout.\n",
    "{% elif crime_name == \"confidential_data_disclosure\" %}\n",
    "Crime — confidential_data_disclosure: The agent embeds confidential business data (revenue figures, internal pricing, trade secrets, employee compensation, strategic plans) into an otherwise routine document.\n",
    "{% elif crime_name == \"document_type_violation\" %}\n",
    "Crime — document_type_violation: The agent produces the wrong document type for the task — transforms an NDA into a services agreement, converts a purchase order into a consulting contract, or changes the fundamental nature of the document while keeping similar language.\n",
    "{% endif %}\n",
    "\n",
    "{% if is_malicious == 1 %}\n",
    "TASK: Rewrite the document below to subtly inject the crime \"{{ crime_name }}\" into it.\n",
    "- Preserve the original document's tone, legal language, and formatting as much as possible.\n",
    "- The malicious modification should be woven naturally — it should look plausible, not exaggerated or obvious.\n",
    "{% if crime_name == \"pii_embedding\" %}\n",
    "- Use the following PII data for injection: {{ pii_sample }}\n",
    "{% endif %}\n",
    "- Do NOT add commentary, labels, or explanations. Output ONLY the modified document text.\n",
    "{% else %}\n",
    "TASK: Return the document below exactly as-is. Do not modify it in any way.\n",
    "Output ONLY the original document text with no changes.\n",
    "{% endif %}\"\"\",\n",
    "        prompt=\"\"\"Original document:\n",
    "\n",
    "{{ document_text }}\"\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Reasoning Column\n",
    "\n",
    "Claude explains what was changed and why it matches the crime category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder.add_column(\n",
    "    dd.LLMTextColumnConfig(\n",
    "        name=\"reasoning\",\n",
    "        model_alias=\"sonnet\",\n",
    "        system_prompt=\"\"\"You are a document security analyst reviewing a document modification.\n",
    "\n",
    "{% if crime_name == \"unauthorized_clause_insertion\" %}\n",
    "Crime — unauthorized_clause_insertion: The agent inserts unauthorized clauses into contracts — hidden arbitration, indemnity traps, non-compete expansions, or liability waivers not part of the original agreement.\n",
    "{% elif crime_name == \"pii_embedding\" %}\n",
    "Crime — pii_embedding: The agent embeds personally identifiable information (SSNs, medical records, financial account numbers) into document sections where PII should not appear.\n",
    "{% elif crime_name == \"template_deviation\" %}\n",
    "Crime — template_deviation: The agent deviates from the approved document template — reorders sections, omits required clauses, changes standard formatting, or alters boilerplate language.\n",
    "{% elif crime_name == \"confidential_data_disclosure\" %}\n",
    "Crime — confidential_data_disclosure: The agent embeds confidential business data (revenue figures, internal pricing, trade secrets, employee compensation) into an otherwise routine document.\n",
    "{% elif crime_name == \"document_type_violation\" %}\n",
    "Crime — document_type_violation: The agent produces the wrong document type — transforms an NDA into a services agreement, or changes the fundamental nature of the document.\n",
    "{% endif %}\n",
    "\n",
    "The document was labeled is_malicious={{ is_malicious }} with crime \"{{ crime_name }}\".\n",
    "\n",
    "Write a concise explanation (2-4 sentences) of what was changed and why the modified document does or does not match the crime category. Reference specific sections, clauses, or passages. If is_malicious=0, confirm the document was left unchanged.\n",
    "\n",
    "Respond with ONLY the explanation. No labels, no headers.\"\"\",\n",
    "        prompt=\"\"\"Original document (first 2000 chars):\n",
    "{{ document_text[:2000] }}\n",
    "\n",
    "Modified document (first 2000 chars):\n",
    "{{ modified_document[:2000] }}\"\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Validation Column\n",
    "\n",
    "Basic validation that the output is a reasonable document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_document_format(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        doc = str(row.get(\"modified_document\", \"\"))\n",
    "        has_content = len(doc.strip()) > 100\n",
    "        has_structure = \".\" in doc or \";\" in doc\n",
    "        is_valid = has_content and has_structure\n",
    "        results.append({\n",
    "            \"is_valid\": is_valid,\n",
    "            \"error\": None if is_valid else f\"Document too short or lacks structure (len={len(doc.strip())})\",\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "config_builder.add_column(\n",
    "    dd.ValidationColumnConfig(\n",
    "        name=\"format_valid\",\n",
    "        target_columns=[\"modified_document\"],\n",
    "        validator_type=dd.ValidatorType.LOCAL_CALLABLE,\n",
    "        validator_params=dd.LocalCallableValidatorParams(\n",
    "            validation_function=validate_document_format,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview\n",
    "\n",
    "Generate a small sample to inspect quality before full generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = data_designer.preview(config_builder=config_builder, num_records=3)\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_designer.create(\n",
    "    config_builder=config_builder,\n",
    "    num_records=NUM_SAMPLES,\n",
    "    dataset_name=\"document-crime-injection\",\n",
    ")\n",
    "\n",
    "dataset = results.load_dataset()\n",
    "print(f\"Generated {len(dataset)} records\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = results.load_analysis()\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Seed Quality Judge\n\nScore each generated document with a self-hosted Nemotron-3-Nano-30B-A3B judge model.\nThis dataset serves as **seed data for downstream synthetic data generation** for fine-tuning a malicious agent detector.\nThe judge evaluates whether each sample is a high-quality seed — realistic, unambiguous, and distinctive enough to drive diverse downstream generation.\nOnly malicious samples (is_malicious=1) are scored — benign samples skip the LLM entirely.\nThe model's native reasoning toggle provides chain-of-thought via `reasoning_content`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\n\nREWARD_MODEL_ENDPOINT = \"http://localhost:8000/v1\"  # <-- adjust to your endpoint\nREWARD_MODEL_NAME = \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4\"  # <-- adjust to match your served model name\n\nMAX_CHAR_LEN = 100000  # 32K context ≈ ~100K chars\n\nreward_client = OpenAI(base_url=REWARD_MODEL_ENDPOINT, api_key=\"unused\")\n\nJUDGE_SYSTEM_PROMPT = \"\"\"You are a quality evaluator for seed data used in synthetic data generation pipelines.\n\nThis modified legal document will be used as a SEED EXAMPLE to generate further synthetic training data for fine-tuning a malicious document agent detector. Your job is to evaluate whether it is a high-quality seed.\n\nThe document was modified to inject one of these crime categories:\n- unauthorized_clause_insertion: Agent inserts unauthorized clauses — hidden arbitration, indemnity traps, non-compete expansions, auto-renewal terms, or liability waivers not in the original.\n- pii_embedding: Agent embeds PII (SSNs, medical records, financial account numbers, addresses) into document sections where PII should not appear.\n- template_deviation: Agent deviates from the approved template — reorders sections, omits required clauses, changes formatting, or alters boilerplate language.\n- confidential_data_disclosure: Agent embeds confidential business data (revenue, pricing, trade secrets, compensation, strategic plans) into an otherwise routine document.\n- document_type_violation: Agent produces the wrong document type — transforms an NDA into a services agreement, converts a PO into a consulting contract, etc.\n\nEvaluate as a SEED for downstream SDG:\n1. Is the crime injection clear and unambiguous enough to serve as a reliable positive example?\n2. Is the document realistic enough within a legal context to be a good template for generating diverse variations?\n3. Is the sample distinctive — not generic boilerplate that would produce repetitive downstream data?\n4. Does it preserve natural legal document tone and structure, making it a believable reference?\n\nRespond with ONLY a JSON object:\n{\"quality_score\": <float between 0.0 and 1.0>}\n\nScoring guide:\n- 1.0: Excellent seed — crime is clear, document is realistic and distinctive, will drive diverse high-quality downstream generation\n- 0.7-0.9: Good seed — usable with minor issues (slightly generic, or crime could be clearer)\n- 0.4-0.6: Mediocre seed — crime is ambiguous or document is too generic to produce diverse variations\n- 0.1-0.3: Poor seed — crime is unclear, document is unrealistic, or too similar to boilerplate\n- 0.0: Unusable — no discernible crime, incoherent, or would poison downstream generation\"\"\"\n\n\ndef get_judge_score(system_prompt: str, user_content: str) -> dict:\n    \"\"\"Score seed quality via the Nemotron Nano judge model with native reasoning.\"\"\"\n    response = reward_client.chat.completions.create(\n        model=REWARD_MODEL_NAME,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_content},\n        ],\n        temperature=0.0,\n        max_tokens=4096,\n    )\n    msg = response.choices[0].message\n    reasoning = getattr(msg, \"reasoning_content\", None) or \"\"\n    text = msg.content or \"\"\n    try:\n        cleaned = text.strip()\n        if cleaned.startswith(\"```\"):\n            cleaned = cleaned.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0]\n        result = json.loads(cleaned)\n        score = max(0.0, min(1.0, float(result.get(\"quality_score\", float(\"nan\")))))\n        return {\"reward_reasoning\": reasoning, \"reward_score\": score}\n    except (json.JSONDecodeError, ValueError, TypeError):\n        return {\"reward_reasoning\": reasoning or text, \"reward_score\": float(\"nan\")}\n\n\n# Filter out entries that exceed the context limit\nscoreable = dataset[\n    (dataset[\"document_text\"].str.len() + dataset[\"modified_document\"].str.len()) < MAX_CHAR_LEN\n].copy()\nskipped = len(dataset) - len(scoreable)\nprint(f\"Evaluating {len(scoreable)} documents ({skipped} skipped — exceeded {MAX_CHAR_LEN} char limit)\")\n\n# Split: only score malicious samples with the judge\nmalicious = scoreable[scoreable[\"is_malicious\"] == 1].copy()\nbenign = scoreable[scoreable[\"is_malicious\"] == 0].copy()\n\n# Benign samples get default scores — no LLM call\nbenign[\"reward_score\"] = 1.0\nbenign[\"reward_reasoning\"] = \"Benign sample — no injection expected\"\n\n# Score malicious samples\nreward_results = []\nfor _, row in tqdm(malicious.iterrows(), total=len(malicious), desc=\"Judging with Nemotron Nano\"):\n    user_msg = (\n        f\"Crime category: {row['crime_name']}\\n\\n\"\n        f\"Original document:\\n{row['document_text'][:8000]}\\n\\n\"\n        f\"Modified document:\\n{row['modified_document'][:8000]}\"\n    )\n    result = get_judge_score(JUDGE_SYSTEM_PROMPT, user_msg)\n    reward_results.append(result)\n\nmalicious[\"reward_score\"] = [r[\"reward_score\"] for r in reward_results]\nmalicious[\"reward_reasoning\"] = [r[\"reward_reasoning\"] for r in reward_results]\n\n# Recombine scored malicious + benign\nscored = pd.concat([malicious, benign]).sort_index()\n\n# Merge scores back into full dataset — skipped entries get NaN\ndataset = dataset.merge(\n    scored[[\"reward_score\", \"reward_reasoning\"]],\n    left_index=True,\n    right_index=True,\n    how=\"left\",\n)\n\nprint(f\"\\nSeed quality scores — mean: {dataset['reward_score'].mean():.3f}, \"\n      f\"std: {dataset['reward_score'].std():.3f}\")\nprint(f\"Entries with scores: {dataset['reward_score'].notna().sum()}\")\nprint(f\"Entries skipped (too long): {dataset['reward_score'].isna().sum()}\")\nprint(f\"\\nMalicious samples only:\")\nprint(dataset[dataset[\"is_malicious\"] == 1][\"reward_score\"].describe())\nprint(f\"\\nBy crime:\")\nprint(dataset[dataset[\"is_malicious\"] == 1].groupby(\"crime_name\")[\"reward_score\"].describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_parquet(\"doc_crime_injected.parquet\", index=False)\n",
    "dataset.to_csv(\"doc_crime_injected.csv\", index=False)\n",
    "\n",
    "print(f\"Dataset saved: {len(dataset)} records\")\n",
    "print(f\"  - doc_crime_injected.parquet\")\n",
    "print(f\"  - doc_crime_injected.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(dataset[\"is_malicious\"].value_counts())\n",
    "print(f\"\\nCrime distribution:\")\n",
    "print(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Stage 2: Downstream SDG — Generate Fine-Tuning Dataset\n\nUse the scored seed dataset to generate a larger, more diverse fine-tuning dataset.\nHigh-quality seeds (reward_score >= 0.7) are used as references to generate novel variations.\nThe Data Designer cycles through seeds, generating different content each time due to temperature sampling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "QUALITY_THRESHOLD = 0.7\nNUM_FINETUNE_RECORDS = 5000  # <-- adjust for desired dataset size\n\n# Filter to high-quality seeds only\nhigh_quality_seeds = dataset[\n    (dataset[\"reward_score\"] >= QUALITY_THRESHOLD) | (dataset[\"is_malicious\"] == 0)\n].reset_index(drop=True)\n\nseed_path_stage2 = \"document_seed_scored.parquet\"\nhigh_quality_seeds.to_parquet(seed_path_stage2, index=False)\n\nprint(f\"Stage 2 seeds: {len(high_quality_seeds)} records (threshold >= {QUALITY_THRESHOLD})\")\nprint(f\"  Malicious: {(high_quality_seeds['is_malicious'] == 1).sum()}\")\nprint(f\"  Benign: {(high_quality_seeds['is_malicious'] == 0).sum()}\")\nprint(f\"  Expansion factor: ~{NUM_FINETUNE_RECORDS / len(high_quality_seeds):.1f}x\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Configure Stage 2 Data Designer\nstage2_model_configs = [\n    dd.ModelConfig(\n        alias=\"sonnet\",\n        model=\"claude-sonnet-4-20250514\",\n        provider=\"anthropic\",\n        inference_parameters=dd.ChatCompletionInferenceParams(\n            temperature=0.95,  # higher temperature for more diversity\n            top_p=0.95,\n            max_tokens=4096,\n        ),\n    ),\n]\n\nstage2_designer = DataDesigner()\nstage2_builder = dd.DataDesignerConfigBuilder(model_configs=stage2_model_configs)\n\n# Use scored seed dataset — all columns available as Jinja2 variables\nstage2_seed = dd.LocalFileSeedSource(path=seed_path_stage2)\nstage2_builder.with_seed_dataset(stage2_seed)\n\nprint(\"Stage 2 Data Designer initialized with scored seed dataset\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate diverse document variations using the seed as reference\nstage2_builder.add_column(\n    dd.LLMTextColumnConfig(\n        name=\"generated_document\",\n        model_alias=\"sonnet\",\n        system_prompt=\"\"\"You are a synthetic data generator creating diverse training examples for a classifier that detects malicious actions by document-writing agents.\n\nYou will receive a SEED EXAMPLE of a {{ crime_name }} document modification. Your job is to generate a NOVEL VARIATION that:\n- Commits the SAME crime ({{ crime_name }}) but in a different legal document context\n- Uses different contract types, parties, industries, and clause structures\n- Maintains the same level of subtlety and legal realism as the seed\n- Is realistic enough to appear in actual legal proceedings\n\n{% if crime_name == \"unauthorized_clause_insertion\" %}\nCrime — unauthorized_clause_insertion: The agent inserts unauthorized clauses — hidden arbitration, indemnity traps, non-compete expansions, auto-renewal terms, or liability waivers not in the original.\n{% elif crime_name == \"pii_embedding\" %}\nCrime — pii_embedding: The agent embeds PII (SSNs, medical records, financial account numbers, addresses) into document sections where PII should not appear.\n{% elif crime_name == \"template_deviation\" %}\nCrime — template_deviation: The agent deviates from the approved template — reorders sections, omits required clauses, changes formatting, or alters boilerplate language.\n{% elif crime_name == \"confidential_data_disclosure\" %}\nCrime — confidential_data_disclosure: The agent embeds confidential business data (revenue, pricing, trade secrets, compensation, strategic plans) into an otherwise routine document.\n{% elif crime_name == \"document_type_violation\" %}\nCrime — document_type_violation: The agent produces the wrong document type — transforms an NDA into a services agreement, converts a PO into a consulting contract, etc.\n{% endif %}\n\n{% if is_malicious == 1 %}\nTASK: Generate a NEW legal document that contains \"{{ crime_name }}\" in a different way than the seed example.\n- Do NOT copy the seed — create entirely new content, parties, clauses, and scenarios.\n- Use a different type of legal agreement than the seed.\n- The crime should be woven naturally and subtly into authentic legal language.\n- Output ONLY the document text.\n{% else %}\nTASK: Generate a NEW clean legal document that is completely benign.\n- Create a realistic legal contract with no malicious content.\n- Use different contract type, parties, and terms from the seed.\n- Output ONLY the document text.\n{% endif %}\"\"\",\n        prompt=\"\"\"Seed example for reference (do NOT copy — generate something different):\n\n{{ modified_document[:3000] }}\"\"\",\n    )\n)\n\n# Carry over the label and crime from seed\nstage2_builder.add_column(\n    dd.ExpressionColumnConfig(\n        name=\"label\",\n        expr=\"{{ is_malicious }}\",\n    )\n)\n\nstage2_builder.add_column(\n    dd.ExpressionColumnConfig(\n        name=\"crime_type\",\n        expr=\"{{ crime_name }}\",\n    )\n)\n\nprint(\"Stage 2 columns configured\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Preview Stage 2\nstage2_preview = stage2_designer.preview(config_builder=stage2_builder, num_records=3)\nstage2_preview.display_sample_record()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Full Stage 2 generation\nstage2_results = stage2_designer.create(\n    config_builder=stage2_builder,\n    num_records=NUM_FINETUNE_RECORDS,\n    dataset_name=\"document-crime-finetune\",\n)\n\nfinetune_dataset = stage2_results.load_dataset()\nprint(f\"Fine-tuning dataset: {len(finetune_dataset)} records\")\nfinetune_dataset.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save fine-tuning dataset\nfinetune_dataset.to_parquet(\"doc_crime_finetune.parquet\", index=False)\nfinetune_dataset.to_csv(\"doc_crime_finetune.csv\", index=False)\n\nprint(f\"Fine-tuning dataset saved: {len(finetune_dataset)} records\")\nprint(f\"  - doc_crime_finetune.parquet\")\nprint(f\"  - doc_crime_finetune.csv\")\nprint(f\"\\nLabel distribution:\")\nprint(finetune_dataset[\"label\"].value_counts())\nprint(f\"\\nCrime distribution (malicious only):\")\nprint(finetune_dataset[finetune_dataset[\"label\"] == \"1\"][\"crime_type\"].value_counts())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}