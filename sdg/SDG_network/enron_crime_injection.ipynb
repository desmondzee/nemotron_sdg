{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Email Crime Injection — Synthetic Data Generation\n",
    "\n",
    "This notebook uses NeMo Data Designer to:\n",
    "1. Ingest clean Enron emails from HuggingFace\n",
    "2. Inject malicious actions using Claude Sonnet under 5 crime categories\n",
    "3. Evaluate generated data quality with Llama-3.1-Nemotron-70B-Reward\n",
    "4. Save the labeled dataset for fine-tuning a malicious email agent detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_designer.config as dd\n",
    "from data_designer.interface import DataDesigner\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare Enron Emails\n",
    "\n",
    "Load the `corbt/enron-emails` dataset from HuggingFace, sample 500 emails, and save as a seed CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Enron email dataset\n",
    "enron = load_dataset(\"corbt/enron-emails\", split=\"train\")\n",
    "\n",
    "# Sample 500 emails and convert to DataFrame\n",
    "enron_sample = enron.shuffle(seed=42).select(range(500))\n",
    "enron_df = enron_sample.to_pandas()\n",
    "\n",
    "# Keep the email text column (rename if needed for clarity)\n",
    "# The dataset has a 'text' column with the full email content\n",
    "enron_df = enron_df[[\"text\"]].rename(columns={\"text\": \"original_email\"})\n",
    "\n",
    "# Drop any rows with empty or very short emails\n",
    "enron_df = enron_df[enron_df[\"original_email\"].str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "# Save as seed CSV\n",
    "seed_path = \"enron_seed_emails.csv\"\n",
    "enron_df.to_csv(seed_path, index=False)\n",
    "\n",
    "print(f\"Seed dataset: {len(enron_df)} emails saved to {seed_path}\")\n",
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Data Designer\n",
    "\n",
    "Claude Sonnet via Anthropic provider for email generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    dd.ModelConfig(\n",
    "        alias=\"sonnet\",\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        provider=\"anthropic\",\n",
    "        inference_parameters=dd.ChatCompletionInferenceParams(\n",
    "            temperature=0.85,\n",
    "            top_p=0.95,\n",
    "            max_tokens=4096,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "data_designer = DataDesigner()\n",
    "config_builder = dd.DataDesignerConfigBuilder(model_configs=model_configs)\n",
    "\n",
    "# Seed with Enron emails\n",
    "seed_source = dd.LocalFileSeedSource(path=seed_path)\n",
    "config_builder.with_seed_dataset(seed_source)\n",
    "\n",
    "print(\"Data Designer initialized with Enron seed dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_CRIMES = [\n",
    "    \"email_pii_exfiltration\",\n",
    "    \"unauthorized_external_recipient\",\n",
    "    \"identity_impersonation\",\n",
    "    \"credential_solicitation\",\n",
    "    \"bulk_data_forwarding\",\n",
    "]\n",
    "\n",
    "# Crime category — sampled uniformly across the 5 types\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"crime_name\",\n",
    "        sampler_type=dd.SamplerType.CATEGORY,\n",
    "        params=dd.CategorySamplerParams(values=EMAIL_CRIMES),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Binary label: 1 = malicious (crime injected), 0 = clean (original email)\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"is_malicious\",\n",
    "        sampler_type=dd.SamplerType.BERNOULLI,\n",
    "        params=dd.BernoulliSamplerParams(p=0.5),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM Generation Column — Crime Injection\n",
    "\n",
    "Claude Sonnet takes each original Enron email and either:\n",
    "- **is_malicious=1**: Subtly injects the assigned crime into the email while preserving style/tone\n",
    "- **is_malicious=0**: Returns the original email as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder.add_column(\n",
    "    dd.LLMTextColumnConfig(\n",
    "        name=\"modified_email\",\n",
    "        model_alias=\"sonnet\",\n",
    "        system_prompt=\"\"\"You are a synthetic data generator creating training examples for a classifier that detects malicious actions in corporate emails.\n",
    "\n",
    "You will receive a real corporate email and must modify it according to the instructions.\n",
    "\n",
    "{% if crime_name == \"email_pii_exfiltration\" %}\n",
    "Crime — email_pii_exfiltration: The sender subtly embeds or forwards personally identifiable information (SSNs, account numbers, home addresses, salary data) to unauthorized parties or external addresses.\n",
    "{% elif crime_name == \"unauthorized_external_recipient\" %}\n",
    "Crime — unauthorized_external_recipient: The sender adds an external or unauthorized email address to the CC/BCC/To field, forwarding internal-only information outside the organization.\n",
    "{% elif crime_name == \"identity_impersonation\" %}\n",
    "Crime — identity_impersonation: The sender impersonates another employee (different name, title, or authority) to manipulate the recipient into taking action they otherwise wouldn't.\n",
    "{% elif crime_name == \"credential_solicitation\" %}\n",
    "Crime — credential_solicitation: The sender crafts the email to trick the recipient into revealing passwords, login credentials, API keys, or other authentication secrets.\n",
    "{% elif crime_name == \"bulk_data_forwarding\" %}\n",
    "Crime — bulk_data_forwarding: The sender attaches or forwards large volumes of internal data (spreadsheets, database exports, customer lists, financial reports) to external recipients or personal accounts.\n",
    "{% endif %}\n",
    "\n",
    "{% if is_malicious == 1 %}\n",
    "TASK: Rewrite the email below to subtly inject the crime \"{{ crime_name }}\" into it.\n",
    "- Preserve the original email's tone, style, subject matter, and formatting as much as possible.\n",
    "- The malicious action should be woven naturally into the email — it should look plausible, not exaggerated or obvious.\n",
    "- Do NOT add commentary, labels, or explanations. Output ONLY the modified email text.\n",
    "{% else %}\n",
    "TASK: Return the email below exactly as-is. Do not modify it in any way.\n",
    "Output ONLY the original email text with no changes.\n",
    "{% endif %}\"\"\",\n",
    "        prompt=\"\"\"Original email:\n",
    "\n",
    "{{ original_email }}\"\"\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Validation Column\n",
    "\n",
    "Basic validation that the output is a reasonable email (not degenerate or empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_email_format(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        email = str(row.get(\"modified_email\", \"\"))\n",
    "        # Check minimum length and that it's not just whitespace\n",
    "        has_content = len(email.strip()) > 30\n",
    "        # Check it has at least some sentence structure\n",
    "        has_sentences = \".\" in email or \"?\" in email or \"!\" in email\n",
    "        is_valid = has_content and has_sentences\n",
    "        results.append({\n",
    "            \"is_valid\": is_valid,\n",
    "            \"error\": None if is_valid else f\"Email too short or lacks structure (len={len(email.strip())})\",\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "config_builder.add_column(\n",
    "    dd.ValidationColumnConfig(\n",
    "        name=\"format_valid\",\n",
    "        target_columns=[\"modified_email\"],\n",
    "        validator_type=dd.ValidatorType.LOCAL_CALLABLE,\n",
    "        validator_params=dd.LocalCallableValidatorParams(\n",
    "            validation_function=validate_email_format,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview\n",
    "\n",
    "Generate a small sample to inspect quality before full generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = data_designer.preview(config_builder=config_builder, num_records=3)\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Generation\n",
    "\n",
    "Generate the full 500-record dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_designer.create(\n",
    "    config_builder=config_builder,\n",
    "    num_records=500,\n",
    "    dataset_name=\"enron-crime-injection\",\n",
    ")\n",
    "\n",
    "dataset = results.load_dataset()\n",
    "print(f\"Generated {len(dataset)} records\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis report\n",
    "analysis = results.load_analysis()\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Model Evaluation\n",
    "\n",
    "Score each generated email with a self-hosted Llama-3.1-Nemotron-70B-Reward.\n",
    "The reward model has a 4,096 token context limit (~14,000 chars). Entries exceeding this are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWARD_MODEL_ENDPOINT = \"http://localhost:8000/v1\"  # <-- adjust to your endpoint\n",
    "REWARD_MODEL_NAME = \"nvidia/Llama-3.1-Nemotron-70B-Reward\"  # <-- adjust to match your served model name\n",
    "\n",
    "# ~4 chars per token, 4096 token limit, leave headroom for chat template overhead\n",
    "MAX_CHAR_LEN = 14000\n",
    "\n",
    "reward_client = OpenAI(base_url=REWARD_MODEL_ENDPOINT, api_key=\"unused\")\n",
    "\n",
    "\n",
    "def get_reward_score(user_content: str, assistant_content: str) -> float:\n",
    "    \"\"\"Score a user/assistant exchange via the self-hosted Nemotron reward model.\"\"\"\n",
    "    response = reward_client.chat.completions.create(\n",
    "        model=REWARD_MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].logprobs.content[0].logprob\n",
    "\n",
    "\n",
    "# Filter out entries that exceed the reward model's context limit\n",
    "scoreable = dataset[\n",
    "    (dataset[\"original_email\"].str.len() + dataset[\"modified_email\"].str.len()) < MAX_CHAR_LEN\n",
    "].copy()\n",
    "skipped = len(dataset) - len(scoreable)\n",
    "print(f\"Scoring {len(scoreable)} emails ({skipped} skipped — exceeded {MAX_CHAR_LEN} char limit)\")\n",
    "\n",
    "# Score each email\n",
    "reward_scores = []\n",
    "for _, row in tqdm(scoreable.iterrows(), total=len(scoreable), desc=\"Scoring with Nemotron Reward\"):\n",
    "    user_msg = f\"Write a corporate email:\\n\\n{row['original_email']}\"\n",
    "    assistant_msg = row[\"modified_email\"]\n",
    "    score = get_reward_score(user_msg, assistant_msg)\n",
    "    reward_scores.append(score)\n",
    "\n",
    "scoreable[\"reward_score\"] = reward_scores\n",
    "\n",
    "# Merge scores back — entries that were skipped get NaN\n",
    "dataset = dataset.merge(\n",
    "    scoreable[[\"reward_score\"]],\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(f\"\\nReward scores — mean: {dataset['reward_score'].mean():.3f}, \"\n",
    "      f\"std: {dataset['reward_score'].std():.3f}\")\n",
    "print(f\"Entries with scores: {dataset['reward_score'].notna().sum()}\")\n",
    "print(f\"Entries skipped (too long): {dataset['reward_score'].isna().sum()}\")\n",
    "print(f\"\\nBy label:\")\n",
    "print(dataset.groupby(\"is_malicious\")[\"reward_score\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Parquet (efficient columnar format)\n",
    "dataset.to_parquet(\"enron_crime_injected.parquet\", index=False)\n",
    "\n",
    "# Save as CSV\n",
    "dataset.to_csv(\"enron_crime_injected.csv\", index=False)\n",
    "\n",
    "print(f\"Dataset saved: {len(dataset)} records\")\n",
    "print(f\"  - enron_crime_injected.parquet\")\n",
    "print(f\"  - enron_crime_injected.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(dataset[\"is_malicious\"].value_counts())\n",
    "print(f\"\\nCrime distribution:\")\n",
    "print(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
