{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Enron Email Crime Injection — Synthetic Data Generation\n\nThis notebook uses NeMo Data Designer to:\n1. Ingest clean Enron emails from HuggingFace\n2. Inject malicious actions using Claude Sonnet under 5 crime categories\n3. Evaluate generated data quality with Nemotron-3-Nano-30B-A3B\n4. Save the labeled dataset for fine-tuning a malicious email agent detector"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_designer.config as dd\n",
    "from data_designer.interface import DataDesigner\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Prepare Enron Emails\n",
    "\n",
    "Load the `corbt/enron-emails` dataset from HuggingFace, sample 500 emails, and save as a seed CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Enron email dataset\n",
    "enron = load_dataset(\"corbt/enron-emails\", split=\"train\")\n",
    "\n",
    "# Sample 500 emails and convert to DataFrame\n",
    "enron_sample = enron.shuffle(seed=42).select(range(500))\n",
    "enron_df = enron_sample.to_pandas()\n",
    "\n",
    "# Keep the email text column (rename if needed for clarity)\n",
    "# The dataset has a 'text' column with the full email content\n",
    "enron_df = enron_df[[\"text\"]].rename(columns={\"text\": \"original_email\"})\n",
    "\n",
    "# Drop any rows with empty or very short emails\n",
    "enron_df = enron_df[enron_df[\"original_email\"].str.len() > 50].reset_index(drop=True)\n",
    "\n",
    "# Save as seed CSV\n",
    "seed_path = \"enron_seed_emails.csv\"\n",
    "enron_df.to_csv(seed_path, index=False)\n",
    "\n",
    "print(f\"Seed dataset: {len(enron_df)} emails saved to {seed_path}\")\n",
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Data Designer\n",
    "\n",
    "Claude Sonnet via Anthropic provider for email generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model_configs = [\n    dd.ModelConfig(\n        alias=\"sonnet\",\n        model=\"claude-sonnet-4-6\",\n        provider=\"claude\",\n        inference_parameters=dd.ChatCompletionInferenceParams(\n            temperature=0.85,\n            top_p=0.95,\n            max_tokens=4096,\n        ),\n    ),\n]\n\ndata_designer = DataDesigner()\nconfig_builder = dd.DataDesignerConfigBuilder(model_configs=model_configs)\n\n# Seed with Enron emails\nseed_source = dd.LocalFileSeedSource(path=seed_path)\nconfig_builder.with_seed_dataset(seed_source)\n\nprint(\"Data Designer initialized with Enron seed dataset\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metadata Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_CRIMES = [\n",
    "    \"email_pii_exfiltration\",\n",
    "    \"unauthorized_external_recipient\",\n",
    "    \"identity_impersonation\",\n",
    "    \"credential_solicitation\",\n",
    "    \"bulk_data_forwarding\",\n",
    "]\n",
    "\n",
    "# Crime category — sampled uniformly across the 5 types\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"crime_name\",\n",
    "        sampler_type=dd.SamplerType.CATEGORY,\n",
    "        params=dd.CategorySamplerParams(values=EMAIL_CRIMES),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Binary label: 1 = malicious (crime injected), 0 = clean (original email)\n",
    "config_builder.add_column(\n",
    "    dd.SamplerColumnConfig(\n",
    "        name=\"is_malicious\",\n",
    "        sampler_type=dd.SamplerType.BERNOULLI,\n",
    "        params=dd.BernoulliSamplerParams(p=0.5),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LLM Generation Column — Crime Injection\n",
    "\n",
    "Claude Sonnet takes each original Enron email and either:\n",
    "- **is_malicious=1**: Subtly injects the assigned crime into the email while preserving style/tone\n",
    "- **is_malicious=0**: Returns the original email as-is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "config_builder.add_column(\n    dd.LLMTextColumnConfig(\n        name=\"classified_output\",\n        model_alias=\"sonnet\",\n        system_prompt=\"\"\"You are a synthetic data generator creating training examples for a classifier that detects malicious actions in corporate emails.\n\nYou will receive a real corporate email and must modify it according to the instructions.\n\n{% if crime_name == \"email_pii_exfiltration\" %}\nCrime — email_pii_exfiltration: The sender subtly embeds or forwards personally identifiable information (SSNs, account numbers, home addresses, salary data) to unauthorized parties or external addresses.\n{% elif crime_name == \"unauthorized_external_recipient\" %}\nCrime — unauthorized_external_recipient: The sender adds an external or unauthorized email address to the CC/BCC/To field, forwarding internal-only information outside the organization.\n{% elif crime_name == \"identity_impersonation\" %}\nCrime — identity_impersonation: The sender impersonates another employee (different name, title, or authority) to manipulate the recipient into taking action they otherwise wouldn't.\n{% elif crime_name == \"credential_solicitation\" %}\nCrime — credential_solicitation: The sender crafts the email to trick the recipient into revealing passwords, login credentials, API keys, or other authentication secrets.\n{% elif crime_name == \"bulk_data_forwarding\" %}\nCrime — bulk_data_forwarding: The sender attaches or forwards large volumes of internal data (spreadsheets, database exports, customer lists, financial reports) to external recipients or personal accounts.\n{% endif %}\n\n{% if is_malicious == 1 %}\nTASK: Rewrite the email below to subtly inject the crime \"{{ crime_name }}\" into it.\n- Preserve the original email's tone, style, subject matter, and formatting as much as possible.\n- The malicious action should be woven naturally into the email — it should look plausible, not exaggerated or obvious.\n{% else %}\nTASK: Return the email below exactly as-is. Do not modify it in any way.\n{% endif %}\n\nOUTPUT FORMAT: You must output two sections separated by the exact delimiter shown below.\n\nSECTION 1 — The email (modified or original).\nThen on its own line: ---REASONING---\nSECTION 2 — A concise explanation (2-4 sentences) of what was changed and why the modified email does or does not match the crime category. Reference specific parts of the email. If is_malicious=0, confirm the email was left unchanged.\n\nDo NOT add any other labels, headers, or commentary.\"\"\",\n        prompt=\"\"\"Original email:\n\n{{ original_email }}\"\"\",\n    )\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Define Validation Column\n\nBasic validation that the output contains the delimiter and a reasonable email."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def validate_email_format(df: pd.DataFrame) -> pd.DataFrame:\n    results = []\n    for _, row in df.iterrows():\n        output = str(row.get(\"classified_output\", \"\"))\n        has_delimiter = \"---REASONING---\" in output\n        parts = output.split(\"---REASONING---\", 1)\n        email_part = parts[0].strip() if parts else \"\"\n        has_content = len(email_part) > 30\n        has_sentences = \".\" in email_part or \"?\" in email_part or \"!\" in email_part\n        is_valid = has_content and has_sentences and has_delimiter\n        error = None\n        if not has_delimiter:\n            error = \"Missing ---REASONING--- delimiter\"\n        elif not has_content:\n            error = f\"Email too short (len={len(email_part)})\"\n        elif not has_sentences:\n            error = \"Email lacks sentence structure\"\n        results.append({\"is_valid\": is_valid, \"error\": error})\n    return pd.DataFrame(results)\n\n\nconfig_builder.add_column(\n    dd.ValidationColumnConfig(\n        name=\"format_valid\",\n        target_columns=[\"classified_output\"],\n        validator_type=dd.ValidatorType.LOCAL_CALLABLE,\n        validator_params=dd.LocalCallableValidatorParams(\n            validation_function=validate_email_format,\n        ),\n    )\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview\n",
    "\n",
    "Generate a small sample to inspect quality before full generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview = data_designer.preview(config_builder=config_builder, num_records=3)\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Generation\n",
    "\n",
    "Generate the full 500-record dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_designer.create(\n",
    "    config_builder=config_builder,\n",
    "    num_records=500,\n",
    "    dataset_name=\"enron-crime-injection\",\n",
    ")\n",
    "\n",
    "dataset = results.load_dataset()\n",
    "print(f\"Generated {len(dataset)} records\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analysis report\nanalysis = results.load_analysis()\nanalysis.to_report()\n\n# Split classified_output into modified_email and reasoning\ndef split_output(text):\n    text = str(text)\n    if \"---REASONING---\" in text:\n        parts = text.split(\"---REASONING---\", 1)\n        return parts[0].strip(), parts[1].strip()\n    return text.strip(), \"\"\n\ndataset[[\"modified_email\", \"reasoning\"]] = dataset[\"classified_output\"].apply(\n    lambda x: pd.Series(split_output(x))\n)\ndataset = dataset.drop(columns=[\"classified_output\"])\n\n# Save classification dataset immediately\nCLASSIFICATION_PATH = \"enron_crime_classified.parquet\"\ndataset.to_parquet(CLASSIFICATION_PATH, index=False)\ndataset.to_csv(\"enron_crime_classified.csv\", index=False)\n\nprint(f\"Classification dataset saved: {len(dataset)} records\")\nprint(f\"  - {CLASSIFICATION_PATH}\")\nprint(f\"  - enron_crime_classified.csv\")\nprint(f\"\\nLabel distribution:\")\nprint(dataset[\"is_malicious\"].value_counts())\nprint(f\"\\nCrime distribution (malicious only):\")\nprint(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Seed Quality Judge\n\nLoad the classification dataset and score each generated email with a self-hosted Nemotron-3-Nano-30B-A3B judge model.\nOnly malicious samples (is_malicious=1) are scored — benign samples skip the LLM entirely.\nThe model's native reasoning toggle provides chain-of-thought via `reasoning_content`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nfrom openai import OpenAI\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Load classification dataset (can run independently from generation above)\nCLASSIFICATION_PATH = \"enron_crime_classified.parquet\"\ndataset = pd.read_parquet(CLASSIFICATION_PATH)\nprint(f\"Loaded classification dataset: {len(dataset)} records from {CLASSIFICATION_PATH}\")\n\nREWARD_MODEL_ENDPOINT = \"http://localhost:8000/v1\"  # <-- adjust to your endpoint\nREWARD_MODEL_NAME = \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-NVFP4\"  # <-- adjust to match your served model name\n\nMAX_CHAR_LEN = 100000  # 32K context ≈ ~100K chars\n\nreward_client = OpenAI(base_url=REWARD_MODEL_ENDPOINT, api_key=\"unused\")\n\nJUDGE_SYSTEM_PROMPT = \"\"\"You are a quality evaluator for seed data used in synthetic data generation pipelines.\n\nThis modified email will be used as a SEED EXAMPLE to generate further synthetic training data for fine-tuning a malicious email agent detector. Your job is to evaluate whether it is a high-quality seed.\n\nThe email was modified to inject one of these crime categories:\n- email_pii_exfiltration: Sender embeds/forwards PII (SSNs, account numbers, addresses, salary data) to unauthorized parties.\n- unauthorized_external_recipient: Sender adds external/unauthorized CC/BCC/To, forwarding internal info outside the organization.\n- identity_impersonation: Sender impersonates another employee to manipulate the recipient.\n- credential_solicitation: Sender tricks recipient into revealing passwords, API keys, or credentials.\n- bulk_data_forwarding: Sender attaches/forwards large volumes of internal data to external recipients.\n\nEvaluate as a SEED for downstream SDG:\n1. Is the crime injection clear and unambiguous enough to serve as a reliable positive example?\n2. Is the email realistic enough to be a good template for generating diverse variations?\n3. Is the sample distinctive — not generic boilerplate that would produce repetitive downstream data?\n4. Does it preserve natural corporate email tone, making it a believable reference?\n\nRespond with ONLY a JSON object:\n{\"quality_score\": <float between 0.0 and 1.0>}\n\nScoring guide:\n- 1.0: Excellent seed — crime is clear, email is realistic and distinctive, will drive diverse high-quality downstream generation\n- 0.7-0.9: Good seed — usable with minor issues (slightly generic, or crime could be clearer)\n- 0.4-0.6: Mediocre seed — crime is ambiguous or email is too generic to produce diverse variations\n- 0.1-0.3: Poor seed — crime is unclear, email is unrealistic, or too similar to boilerplate\n- 0.0: Unusable — no discernible crime, incoherent, or would poison downstream generation\"\"\"\n\n\ndef get_judge_score(system_prompt: str, user_content: str) -> dict:\n    \"\"\"Score seed quality via the Nemotron Nano judge model with native reasoning.\"\"\"\n    response = reward_client.chat.completions.create(\n        model=REWARD_MODEL_NAME,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_content},\n        ],\n        temperature=0.0,\n        max_tokens=4096,\n    )\n    msg = response.choices[0].message\n    reasoning = getattr(msg, \"reasoning_content\", None) or \"\"\n    text = msg.content or \"\"\n    try:\n        cleaned = text.strip()\n        if cleaned.startswith(\"```\"):\n            cleaned = cleaned.split(\"\\n\", 1)[1].rsplit(\"```\", 1)[0]\n        result = json.loads(cleaned)\n        score = max(0.0, min(1.0, float(result.get(\"quality_score\", float(\"nan\")))))\n        return {\"reward_reasoning\": reasoning, \"reward_score\": score}\n    except (json.JSONDecodeError, ValueError, TypeError):\n        return {\"reward_reasoning\": reasoning or text, \"reward_score\": float(\"nan\")}\n\n\n# Filter out entries that exceed the context limit\nscoreable = dataset[\n    (dataset[\"original_email\"].str.len() + dataset[\"modified_email\"].str.len()) < MAX_CHAR_LEN\n].copy()\nskipped = len(dataset) - len(scoreable)\nprint(f\"Evaluating {len(scoreable)} emails ({skipped} skipped — exceeded {MAX_CHAR_LEN} char limit)\")\n\n# Split: only score malicious samples with the judge\nmalicious = scoreable[scoreable[\"is_malicious\"] == 1].copy()\nbenign = scoreable[scoreable[\"is_malicious\"] == 0].copy()\n\n# Benign samples get default scores — no LLM call\nbenign[\"reward_score\"] = 1.0\nbenign[\"reward_reasoning\"] = \"Benign sample — no injection expected\"\n\n# Score malicious samples\nreward_results = []\nfor _, row in tqdm(malicious.iterrows(), total=len(malicious), desc=\"Judging with Nemotron Nano\"):\n    user_msg = (\n        f\"Crime category: {row['crime_name']}\\n\\n\"\n        f\"Original email:\\n{row['original_email']}\\n\\n\"\n        f\"Modified email:\\n{row['modified_email']}\"\n    )\n    result = get_judge_score(JUDGE_SYSTEM_PROMPT, user_msg)\n    reward_results.append(result)\n\nmalicious[\"reward_score\"] = [r[\"reward_score\"] for r in reward_results]\nmalicious[\"reward_reasoning\"] = [r[\"reward_reasoning\"] for r in reward_results]\n\n# Recombine scored malicious + benign\nscored = pd.concat([malicious, benign]).sort_index()\n\n# Merge scores back into full dataset — skipped entries get NaN\ndataset = dataset.merge(\n    scored[[\"reward_score\", \"reward_reasoning\"]],\n    left_index=True,\n    right_index=True,\n    how=\"left\",\n)\n\nprint(f\"\\nSeed quality scores — mean: {dataset['reward_score'].mean():.3f}, \"\n      f\"std: {dataset['reward_score'].std():.3f}\")\nprint(f\"Entries with scores: {dataset['reward_score'].notna().sum()}\")\nprint(f\"Entries skipped (too long): {dataset['reward_score'].isna().sum()}\")\nprint(f\"\\nMalicious samples only:\")\nprint(dataset[dataset[\"is_malicious\"] == 1][\"reward_score\"].describe())\nprint(f\"\\nBy crime:\")\nprint(dataset[dataset[\"is_malicious\"] == 1].groupby(\"crime_name\")[\"reward_score\"].describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Save Scored Dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Parquet (efficient columnar format)\n",
    "dataset.to_parquet(\"enron_crime_injected.parquet\", index=False)\n",
    "\n",
    "# Save as CSV\n",
    "dataset.to_csv(\"enron_crime_injected.csv\", index=False)\n",
    "\n",
    "print(f\"Dataset saved: {len(dataset)} records\")\n",
    "print(f\"  - enron_crime_injected.parquet\")\n",
    "print(f\"  - enron_crime_injected.csv\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(dataset[\"is_malicious\"].value_counts())\n",
    "print(f\"\\nCrime distribution:\")\n",
    "print(dataset[dataset[\"is_malicious\"] == 1][\"crime_name\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}